2024-10-04 16:09:22,667 - mmpose - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.3.r11.3/compiler.29745058_0
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 1.10.2+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.3+cu111
OpenCV: 4.8.0
MMCV: 1.3.17
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 11.1
MMPose: 0.28.1+4e711d4
------------------------------------------------------------

2024-10-04 16:09:22,667 - mmpose - INFO - Distributed training: False
2024-10-04 16:09:23,584 - mmpose - INFO - Config:
log_level = 'INFO'
load_from = None
resume_from = None
dist_params = dict(backend='nccl')
workflow = [('train', 1)]
checkpoint_config = dict(interval=5)
evaluation = dict(
    interval=5, metric='PCK', key_indicator='PCK', gpu_collect=True)
optimizer = dict(
    type='Adam',
    lr=0.0002,
    paramwise_cfg=dict(custom_keys=dict(encoder_sample=dict(lr_mult=0.1))))
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=1000,
    warmup_ratio=0.001,
    min_lr_ratio=1e-05)
total_epochs = 210
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
channel_cfg = dict(
    num_output_channels=1,
    dataset_joints=1,
    dataset_channel=[[0]],
    inference_channel=[0],
    max_kpt_num=100)
extra = dict(
    PRETRAINED_LAYERS=('conv1', 'bn1', 'conv2', 'bn2', 'layer1', 'transition1',
                       'stage2', 'transition2', 'stage3'),
    FINAL_CONV_KERNEL=1,
    STAGE2=dict(
        NUM_MODULES=1,
        NUM_BRANCHES=2,
        BLOCK='BASIC',
        NUM_BLOCKS=(4, 4),
        NUM_CHANNELS=(32, 64),
        FUSE_METHOD='SUM'),
    STAGE3=dict(
        NUM_MODULES=4,
        NUM_BRANCHES=3,
        BLOCK='BASIC',
        NUM_BLOCKS=(4, 4, 4),
        NUM_CHANNELS=(32, 64, 128),
        FUSE_METHOD='SUM'))
model = dict(
    type='TransformerPose',
    pretrained='torchvision://resnet50',
    encoder_sample=dict(type='ResNet', depth=50),
    encoder_query=dict(type='ResNet', depth=50),
    keypoint_head=dict(
        type='TokenPose_TB_base',
        in_channels=2048,
        transformer=dict(
            type='Transformer',
            dim=256,
            depth=4,
            heads=8,
            mlp_dim=512,
            dropout=0.1,
            num_keypoints=100,
            all_attn=False,
            scale_with_head=True),
        train_cfg=None,
        test_cfg=None,
        dim=256,
        hidden_heatmap_dim=384,
        heatmap_dim=4096,
        apply_multi=True,
        apply_init=True,
        loss_keypoint=dict(type='JointsMSELoss', use_target_weight=True)),
    train_cfg=dict(),
    test_cfg=dict(
        flip_test=False,
        post_process='default',
        shift_heatmap=True,
        modulate_kernel=11))
data_cfg = dict(
    image_size=[256, 256],
    heatmap_size=[64, 64],
    num_output_channels=1,
    num_joints=1,
    dataset_channel=[[0]],
    inference_channel=[0])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='TopDownGetRandomScaleRotation', rot_factor=15,
        scale_factor=0.15),
    dict(type='TopDownAffineFewShot'),
    dict(type='ToTensor'),
    dict(
        type='NormalizeTensor',
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]),
    dict(type='TopDownGenerateTargetFewShot', sigma=2),
    dict(
        type='Collect',
        keys=['img', 'target', 'target_weight'],
        meta_keys=[
            'image_file', 'joints_3d', 'joints_3d_visible', 'center', 'scale',
            'rotation', 'bbox_score', 'flip_pairs', 'category_id', 'flip',
            'pair'
        ])
]
valid_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='TopDownAffineFewShot'),
    dict(type='ToTensor'),
    dict(
        type='NormalizeTensor',
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]),
    dict(type='TopDownGenerateTargetFewShot', sigma=2),
    dict(
        type='Collect',
        keys=['img', 'target', 'target_weight'],
        meta_keys=[
            'image_file', 'joints_3d', 'joints_3d_visible', 'center', 'scale',
            'rotation', 'bbox_score', 'flip_pairs', 'category_id', 'flip',
            'pair'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='TopDownAffineFewShot'),
    dict(type='ToTensor'),
    dict(
        type='NormalizeTensor',
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]),
    dict(type='TopDownGenerateTargetFewShot', sigma=2),
    dict(
        type='Collect',
        keys=['img', 'target', 'target_weight'],
        meta_keys=[
            'image_file', 'joints_3d', 'joints_3d_visible', 'center', 'scale',
            'rotation', 'bbox_score', 'flip_pairs', 'category_id', 'flip',
            'pair'
        ])
]
data_root = '/data/yjliang/code/Category-Agnostic-Pose-Estimation/P2/zero-shot-CAPE/Pose-for-Everything/data/mp100'
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=8,
    train=dict(
        type='TransformerPoseDataset',
        ann_file=
        '/data/yjliang/code/Category-Agnostic-Pose-Estimation/P2/zero-shot-CAPE/Pose-for-Everything/data/mp100/annotations/mp100_split1_train.json',
        img_prefix=
        '/data/yjliang/code/Category-Agnostic-Pose-Estimation/P2/zero-shot-CAPE/Pose-for-Everything/data/mp100/',
        data_cfg=dict(
            image_size=[256, 256],
            heatmap_size=[64, 64],
            num_output_channels=1,
            num_joints=1,
            dataset_channel=[[0]],
            inference_channel=[0]),
        valid_class_ids=None,
        max_kpt_num=100,
        num_shots=1,
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='TopDownGetRandomScaleRotation',
                rot_factor=15,
                scale_factor=0.15),
            dict(type='TopDownAffineFewShot'),
            dict(type='ToTensor'),
            dict(
                type='NormalizeTensor',
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]),
            dict(type='TopDownGenerateTargetFewShot', sigma=2),
            dict(
                type='Collect',
                keys=['img', 'target', 'target_weight'],
                meta_keys=[
                    'image_file', 'joints_3d', 'joints_3d_visible', 'center',
                    'scale', 'rotation', 'bbox_score', 'flip_pairs',
                    'category_id', 'flip', 'pair'
                ])
        ]),
    val=dict(
        type='TransformerPoseDataset',
        ann_file=
        '/data/yjliang/code/Category-Agnostic-Pose-Estimation/P2/zero-shot-CAPE/Pose-for-Everything/data/mp100/annotations/mp100_split1_test.json',
        img_prefix=
        '/data/yjliang/code/Category-Agnostic-Pose-Estimation/P2/zero-shot-CAPE/Pose-for-Everything/data/mp100/',
        data_cfg=dict(
            image_size=[256, 256],
            heatmap_size=[64, 64],
            num_output_channels=1,
            num_joints=1,
            dataset_channel=[[0]],
            inference_channel=[0]),
        valid_class_ids=None,
        max_kpt_num=100,
        num_shots=1,
        num_queries=15,
        num_episodes=200,
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='TopDownAffineFewShot'),
            dict(type='ToTensor'),
            dict(
                type='NormalizeTensor',
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]),
            dict(type='TopDownGenerateTargetFewShot', sigma=2),
            dict(
                type='Collect',
                keys=['img', 'target', 'target_weight'],
                meta_keys=[
                    'image_file', 'joints_3d', 'joints_3d_visible', 'center',
                    'scale', 'rotation', 'bbox_score', 'flip_pairs',
                    'category_id', 'flip', 'pair'
                ])
        ]),
    test=dict(
        type='TransformerPoseDataset',
        ann_file=
        '/data/yjliang/code/Category-Agnostic-Pose-Estimation/P2/zero-shot-CAPE/Pose-for-Everything/data/mp100/annotations/mp100_split1_test.json',
        img_prefix=
        '/data/yjliang/code/Category-Agnostic-Pose-Estimation/P2/zero-shot-CAPE/Pose-for-Everything/data/mp100/',
        data_cfg=dict(
            image_size=[256, 256],
            heatmap_size=[64, 64],
            num_output_channels=1,
            num_joints=1,
            dataset_channel=[[0]],
            inference_channel=[0]),
        valid_class_ids=None,
        max_kpt_num=100,
        num_shots=1,
        num_queries=15,
        num_episodes=200,
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='TopDownAffineFewShot'),
            dict(type='ToTensor'),
            dict(
                type='NormalizeTensor',
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]),
            dict(type='TopDownGenerateTargetFewShot', sigma=2),
            dict(
                type='Collect',
                keys=['img', 'target', 'target_weight'],
                meta_keys=[
                    'image_file', 'joints_3d', 'joints_3d_visible', 'center',
                    'scale', 'rotation', 'bbox_score', 'flip_pairs',
                    'category_id', 'flip', 'pair'
                ])
        ]))
shuffle_cfg = dict(interval=1)
work_dir = 'work_dirs/scape_spilt1'
gpu_ids = range(0, 1)

2024-10-04 16:09:23,585 - mmpose - INFO - Set random seed to 1, deterministic: True
2024-10-04 16:09:31,483 - mmpose - INFO - Start running, host: yjliang@amax, work_dir: /data/yjliang/code/Category-Agnostic-Pose-Estimation/P2/SCAPE/tools/work_dirs/scape_spilt1
2024-10-04 16:09:31,483 - mmpose - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) ShufflePairedSamplesHook           
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2024-10-04 16:09:31,484 - mmpose - INFO - workflow: [('train', 1)], max: 210 epochs
2024-10-04 16:09:31,484 - mmpose - INFO - Checkpoints will be saved to /data/yjliang/code/Category-Agnostic-Pose-Estimation/P2/SCAPE/tools/work_dirs/scape_spilt1 by HardDiskBackend.
2024-10-04 16:09:52,476 - mmpose - INFO - Epoch [1][50/949]	lr: 9.990e-07, eta: 23:13:52, time: 0.420, data_time: 0.108, memory: 4606, l1_loss_layer0: 0.9058, acc_pose: 0.0181, loss: 0.9058
2024-10-04 16:10:09,194 - mmpose - INFO - Epoch [1][100/949]	lr: 1.998e-06, eta: 20:51:44, time: 0.334, data_time: 0.028, memory: 4606, l1_loss_layer0: 0.3955, acc_pose: 0.2515, loss: 0.3955
2024-10-04 16:10:25,841 - mmpose - INFO - Epoch [1][150/949]	lr: 2.997e-06, eta: 20:02:35, time: 0.333, data_time: 0.029, memory: 4606, l1_loss_layer0: 0.3238, acc_pose: 0.4011, loss: 0.3238
2024-10-04 16:10:42,374 - mmpose - INFO - Epoch [1][200/949]	lr: 3.996e-06, eta: 19:36:00, time: 0.331, data_time: 0.028, memory: 4606, l1_loss_layer0: 0.2915, acc_pose: 0.5043, loss: 0.2915
2024-10-04 16:10:59,086 - mmpose - INFO - Epoch [1][250/949]	lr: 4.995e-06, eta: 19:22:18, time: 0.334, data_time: 0.029, memory: 4606, l1_loss_layer0: 0.2827, acc_pose: 0.5491, loss: 0.2827
2024-10-04 16:11:16,039 - mmpose - INFO - Epoch [1][300/949]	lr: 5.994e-06, eta: 19:15:44, time: 0.339, data_time: 0.028, memory: 4606, l1_loss_layer0: 0.2745, acc_pose: 0.5440, loss: 0.2745
2024-10-04 16:11:32,980 - mmpose - INFO - Epoch [1][350/949]	lr: 6.993e-06, eta: 19:10:51, time: 0.339, data_time: 0.029, memory: 4606, l1_loss_layer0: 0.2701, acc_pose: 0.5496, loss: 0.2701
2024-10-04 16:11:49,613 - mmpose - INFO - Epoch [1][400/949]	lr: 7.992e-06, eta: 19:04:33, time: 0.333, data_time: 0.028, memory: 4606, l1_loss_layer0: 0.2674, acc_pose: 0.6099, loss: 0.2674
2024-10-04 16:12:06,138 - mmpose - INFO - Epoch [1][450/949]	lr: 8.991e-06, eta: 18:58:50, time: 0.331, data_time: 0.029, memory: 4606, l1_loss_layer0: 0.2597, acc_pose: 0.6081, loss: 0.2597
2024-10-04 16:12:22,321 - mmpose - INFO - Epoch [1][500/949]	lr: 9.990e-06, eta: 18:51:55, time: 0.324, data_time: 0.028, memory: 4606, l1_loss_layer0: 0.2587, acc_pose: 0.6547, loss: 0.2587
2024-10-04 16:12:38,932 - mmpose - INFO - Epoch [1][550/949]	lr: 1.099e-05, eta: 18:48:47, time: 0.332, data_time: 0.029, memory: 4606, l1_loss_layer0: 0.2507, acc_pose: 0.6821, loss: 0.2507
